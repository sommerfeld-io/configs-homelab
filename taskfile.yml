---
version: '3.42.1'

vars:
  INSPEC_IMAGE: chef/inspec:5.22.76

tasks:

  cleanup:
    desc: 'Cleanup the environment'
    cmds:
      - docker compose up cleanup
      - docker compose down --remove-orphans

  # ===============================================================================================

  lint:
    desc: 'Run all project linters outside of Dockerfile linters'
    cmds:
      - for:
          matrix:
            LINTER: ['yaml', 'workflows', 'filenames', 'folders', 'markdown-links', 'ansible', 'helm', 'k8s-manifests']
        cmd: docker compose up lint-{{.ITEM.LINTER}} --exit-code-from lint-{{.ITEM.LINTER}}

  # ===============================================================================================

  docs:run:
    desc: 'Run the documentation server'
    cmds:
      - docker compose up docs-dev-server

  # ===============================================================================================

  host:conky:
    desc: 'HOST ONLY | (Re-)start conky'
    dir: components/conky
    cmds:
      - killall conky || true
      - ./run.sh

  # ===============================================================================================

  host:ansible:cleanup:
    vars:
      PLAYBOOK: cleanup.yml
    desc: &ansible-desc 'HOST ONLY | Run Ansible playbook | {{.PLAYBOOK}}'
    dir: &ansible-dir components/ansible
    cmds: &ansible-cmd
      - ansible-playbook "playbooks/{{.PLAYBOOK}}" --inventory hosts.yml --ask-become-pass

  host:ansible:raspi:
    vars:
      PLAYBOOK: raspi.yml
    desc: *ansible-desc
    dir: *ansible-dir
    cmds: *ansible-cmd

  host:ansible:ubuntu:desktop:
    vars:
      PLAYBOOK: ubuntu-desktop.yml
    desc: *ansible-desc
    dir: *ansible-dir
    cmds: *ansible-cmd

  host:ansible:ubuntu:desktop-steam:
    vars:
      PLAYBOOK: ubuntu-desktop-steam.yml
    desc: *ansible-desc
    dir: *ansible-dir
    cmds: *ansible-cmd

  # ===============================================================================================

  inspec:check:all:
    desc: 'HOST ONLY | Vendor and check InSpec profile validity'
    cmds:
      - for: ['ansible-baseline']
        task: inspec:check:{{.ITEM}}

  inspec:check:*:
    desc: 'HOST ONLY | Vendor and check InSpec profile validity'
    vars:
      PROFILE: '{{index .MATCH 0}}'
    cmds:
      - rm -f "tests/inspec/{{.PROFILE}}/inspec.lock"
      - docker compose run --rm inspec vendor "tests/inspec/{{.PROFILE}}" --overwrite --chef-license=accept
      - docker compose run --rm inspec check "tests/inspec/{{.PROFILE}}" --chef-license=accept

  host:test:inspec:ansible-baseline:all:
    desc: 'HOST ONLY | Run InSpec against all nodes'
    dir: &inspec-dir tests/inspec
    deps:
      - task: inspec:check
    cmds:
      - for: ['caprica.fritz.box', 'kobol.fritz.box']
        task: host:test:inspec:ansible-baseline:{{.ITEM}}

  host:test:inspec:ansible-baseline:*:
    desc: 'HOST ONLY | Run InSpec against single node | (* = FQDN)'
    vars:
      HOST: '{{index .MATCH 0}}'
      USER: sebastian
      PROFILE: ansible-baseline
    cmds:
      - docker compose run --rm --env SSH_AUTH_SOCK=/ssh-auth.sock -v "$SSH_AUTH_SOCK:/ssh-auth.sock" inspec exec "tests/inspec/{{.PROFILE}}" --target "ssh://{{.USER}}@{{.HOST}}" --no-distinct-exit --chef-license=accept

  # ===============================================================================================

  host:virtual-talos-admin:start:
    desc: 'HOST ONLY | Startup the Talos Administration Vagrantbox'
    dir: &talos-vm-dir components/talos-cluster/virtual-talos-admin
    cmds:
      - vagrant validate
      - vagrant up
      - vagrant ssh

  host:virtual-talos-admin:stop:
    desc: 'HOST ONLY | Shutdown the Talos Administration Vagrantbox'
    dir: *talos-vm-dir
    cmds:
      - vagrant halt

  host:virtual-talos-admin:remove:
    desc: 'HOST ONLY | Remove the Talos Administration Vagrantbox'
    dir: *talos-vm-dir
    cmds:
      - vagrant halt
      - vagrant destroy --force
